{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f541d677-dce5-4bd7-87c2-3c674d72330e",
   "metadata": {},
   "source": [
    "#### 1 tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8ad3ba5-73aa-4ad9-9e6a-41159a5d4ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: I love learning natural language processing\n",
      "Tokenized text: ['i', 'love', 'learning', 'natural', 'language', 'processing']\n",
      "Token IDs: [1045, 2293, 4083, 3019, 2653, 6364]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Text example\n",
    "text = \"I love learning natural language processing\"\n",
    "\n",
    "# Tokenize the text\n",
    "tokens = tokenizer.tokenize(text)\n",
    "print(f\"Original text: {text}\")\n",
    "print(f\"Tokenized text: {tokens}\")\n",
    "\n",
    "# Convert tokens to IDs\n",
    "input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(f\"Token IDs: {input_ids}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f865cd-745c-4cde-95bd-d0c75e4d7e77",
   "metadata": {},
   "source": [
    "#### 2. Sentiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90f480d3-54f9-4e68-bdb2-3bc78e7c7f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: POSITIVE\n",
      "Confidence: 0.9361\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "model_name=\"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# Create a sentiment analysis pipeline\n",
    "sentiment_analyzer = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=model_name, tokenizer= tokenizer\n",
    ")\n",
    "\n",
    "# Test text\n",
    "text = \"I must to learn natural language processing\"\n",
    "\n",
    "# Get the sentiment\n",
    "result = sentiment_analyzer(text)\n",
    "print(f\"Sentiment: {result[0]['label']}\")\n",
    "print(f\"Confidence: {result[0]['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb144ea-a2bd-473b-88b5-beeb376507ce",
   "metadata": {},
   "source": [
    "#### 3. NER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "701cbc4d-feea-4530-b20c-1b1e4094f12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yan - B-PER - 1.00\n",
      "Le - I-PER - 1.00\n",
      "##C - I-PER - 1.00\n",
      "##un - I-PER - 0.84\n",
      "Facebook - B-ORG - 0.90\n",
      "Fr - B-LOC - 0.93\n",
      "##an - I-LOC - 0.94\n",
      "##cia - I-LOC - 0.92\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "from transformers import pipeline\n",
    "\n",
    "# Cargar el modelo y el tokenizador\n",
    "model_name = \"dslim/bert-base-NER\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "\n",
    "# Crear el pipeline de NER\n",
    "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Texto de prueba\n",
    "texto = \"El doctor Yan LeCun trabaja en Facebook y vive en Francia.\"\n",
    "\n",
    "# Obtener entidades\n",
    "entidades = ner_pipeline(texto)\n",
    "\n",
    "# Mostrar resultados\n",
    "for entidad in entidades:\n",
    "    print(f\"{entidad['word']} - {entidad['entity']} - {entidad['score']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7d0e916-5645-4ab6-aafa-b6787cd9184d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: Apple\n",
      "Type: ORG\n",
      "Confidence: 0.9979\n",
      "------------------------------\n",
      "Entity: Tomás Arteaga\n",
      "Type: PER\n",
      "Confidence: 0.9986\n",
      "------------------------------\n",
      "Entity: iPhone\n",
      "Type: MISC\n",
      "Confidence: 0.9939\n",
      "------------------------------\n",
      "Entity: California\n",
      "Type: LOC\n",
      "Confidence: 0.9997\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "# Initialize the NER pipeline\n",
    "model_name=\"dbmdz/bert-large-cased-finetuned-conll03-english\"\n",
    "ner_pipeline = pipeline(\"ner\", model=model_name, aggregation_strategy=\"simple\")\n",
    "# Text example\n",
    "text = \"Apple CEO tim Cook announced new iPhone models in California yesterday.\"\n",
    "# Perform NER\n",
    "entities = ner_pipeline(text)\n",
    "# Print the results\n",
    "for entity in entities:\n",
    "    print(f\"Entity: {entity['word']}\")\n",
    "    print(f\"Type: {entity['entity_group']}\")\n",
    "    print(f\"Confidence: {entity['score']:.4f}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f834fe-6886-4e00-a5fe-6d53c7b5212b",
   "metadata": {},
   "source": [
    "#### 4. Summarization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "090f1e57-87ff-4b2d-9d8b-0ac62ba655f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The Jebel is a mountain so narrow that its tracery on the map gives it a likeness to a caterpillar crawling from the south to the north . Its feet are well covered by sands tossed from the Euphrates, there to\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "\n",
    "# Cargar el modelo y el tokenizador\n",
    "modelo = \"sshleifer/distilbart-cnn-12-6\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelo)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(modelo)\n",
    "\n",
    "# Crear el pipeline de resumen\n",
    "summarization_pipeline = pipeline(\"summarization\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Texto de ejemplo\n",
    "texto = \"\"\"The Jebel es Zubleh is a mountain fifty miles and more in length, and so narrow that its tracery on the map gives it a likeness to a caterpillar crawling from the south to the north. Standing on its red-and-white cliffs, and looking off under the path of the rising sun, one sees only the Desert of Arabia, where the east winds, so hateful to vinegrowers of Jericho, have kept their playgrounds since the beginning. Its feet are well covered by sands tossed from the Euphrates, there to lie, for the mountain is a wall to the pasture-lands of Moab and Ammon on the west—lands which else had been of the desert a part.\n",
    "The Arab has impressed his language upon everything south and east of Judea, so, in his tongue, the old Jebel is the parent of numberless wadies which, intersecting the Roman road—now a dim suggestion of what once it was, a dusty path for Syrian pilgrims to and from Mecca—run their furrows, deepening as they go, to pass the torrents of the rainy season into the Jordan, or their last receptacle, the Dead Sea. Out of one of these wadies—or, more particularly, out of that one which rises at the extreme end of the Jebel, and, extending east of north, becomes at length the bed of the Jabbok River—a traveller passed, going to the table-lands of the desert. To this person the attention of the reader is first besought.\"\"\"\n",
    "\n",
    "# Generar resumen\n",
    "resumen = summarization_pipeline(texto, max_length=50, min_length=20, do_sample=False)\n",
    "\n",
    "# Mostrar el resumen\n",
    "print(resumen[0]['summary_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "89b2fe28-12a6-4819-b2a7-8cbc0f42b081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' The Jebel is a mountain so narrow that its tracery on the map gives it a likeness to a caterpillar crawling from the south to the north . Its feet are well covered by sands tossed from the Euphrates, there to'}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "23265438-bfeb-426f-8313-ca2851662e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La révolution de l'intelligence artificielle change le monde.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Cargar el modelo y el tokenizador\n",
    "modelo = \"t5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelo)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(modelo)\n",
    "\n",
    "# Texto en inglés\n",
    "texto_origen =\"The artificial intelligence revolution is changing the world.\"\n",
    "# Preprocesar el texto para traducción\n",
    "entrada = f\"translate English to French: {texto_origen}\"\n",
    "tokens = tokenizer.encode(entrada, return_tensors=\"pt\")\n",
    "\n",
    "# Generar traducción\n",
    "output_tokens = model.generate(tokens, max_length=50)\n",
    "traduccion = tokenizer.decode(output_tokens[0], skip_special_tokens=True)\n",
    "\n",
    "# Mostrar la traducción\n",
    "print(traduccion)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 NLP",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
